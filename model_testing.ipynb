{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from recommender.read_db import ReadDatabase\n",
    "from recommender.models import CollaborativeFiltering\n",
    "from recommender.preprocess import SetUpDataframes\n",
    "from recommender.datasets import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "# environment variables\n",
    "DB_URI = os.environ.get(\"DB_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up database reader\n",
    "engine = create_engine(DB_URI)\n",
    "reader_cm = ReadDatabase(engine, 'CM_BD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_data(filename):\n",
    "    question_df = reader_cm.get_data(\n",
    "        'id, post_id',\n",
    "        'posts_question',\n",
    "        None)\n",
    "\n",
    "    taxonomy_df = reader_cm.get_data(\n",
    "        'post_id, area_id',\n",
    "        'posts_taxonomy',\n",
    "        None)\n",
    "\n",
    "    content_df = reader_cm.get_data(\n",
    "        'id, min_range, max_range',\n",
    "        'posts_post',\n",
    "        \"status IN ('published')\")\n",
    "\n",
    "    interaction_df = reader_cm.get_data(\n",
    "        'user_id, post_id',\n",
    "        'posts_interaction',\n",
    "        \"type IN ('sended', 'sent', 'dispatched')\")\n",
    "    interaction_df = interaction_df[~interaction_df['post_id'].isna()]\n",
    "    interaction_df['post_id'] = interaction_df['post_id'].astype('int32')\n",
    "\n",
    "    response_df = reader_cm.get_data(\n",
    "        'user_id, response, question_id',\n",
    "        'posts_response',\n",
    "        \"created_at >= '2019-09-20'\",\n",
    "        None)\n",
    "    response_df = response_df[\n",
    "        (response_df['response'].apply(lambda x: x.isdigit())) & (response_df['response'] != '0')]\n",
    "    response_df = response_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    fresh_data = {\n",
    "        'question_df': question_df.to_json(),\n",
    "        'taxonomy_df': taxonomy_df.to_json(),\n",
    "        'content_df': content_df.to_json(),\n",
    "        'interaction_df': interaction_df.to_json(),\n",
    "        'response_df': response_df.to_json()\n",
    "    }\n",
    "\n",
    "    with open(f'{filename}.pkl', 'wb') as f:\n",
    "        pickle.dump(fresh_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, months, data_required):\n",
    "    model = CollaborativeFiltering()\n",
    "\n",
    "    model.load_model('afinidata_recommender_model_specs')\n",
    "\n",
    "    return model.afinidata_recommend(user_id=user_id, months=months, data_required=data_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_recommendation_response(user_id, response):\n",
    "    recommendation_df = pd.read_json(recommend(user_id, 0, fresh_data))\n",
    "    post_id = recommendation_df.iloc[0]['post_id']\n",
    "    question_id = recommendation_df.iloc[0]['question_id']\n",
    "    print(recommendation_df.iloc[0])\n",
    "    \n",
    "    new_response = pd.DataFrame([[user_id, response, question_id]], columns=['user_id', 'response', 'question_id'])\n",
    "    response_df = pd.read_json(fresh_data['response_df']).append(new_response, ignore_index=True)\n",
    "    fresh_data['response_df'] = response_df.to_json()\n",
    "\n",
    "    new_interaction = pd.DataFrame([[user_id, post_id]], columns=['user_id', 'post_id'])\n",
    "    interaction_df = pd.read_json(fresh_data['interaction_df']).append(new_interaction, ignore_index=True)\n",
    "    fresh_data['interaction_df'] = interaction_df.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "reading columns id, post_id from table posts_question from database CM_BD\n",
      "----------------------------------------------------------------------\n",
      "reading columns post_id, area_id from table posts_taxonomy from database CM_BD\n",
      "----------------------------------------------------------------------\n",
      "reading columns id, min_range, max_range from table posts_post from database CM_BD\n",
      "----------------------------------------------------------------------\n",
      "reading columns user_id, post_id from table posts_interaction from database CM_BD\n",
      "----------------------------------------------------------------------\n",
      "reading columns user_id, response, question_id from table posts_response from database CM_BD\n"
     ]
    }
   ],
   "source": [
    "refresh_data('afinidata_fresh_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'afinidata_fresh_data.pkl', 'rb') as f:\n",
    "    fresh_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "total number of responses in response_df: 6547\n"
     ]
    }
   ],
   "source": [
    "# extract data from posts_response into a pandas dataframe and\n",
    "# slightly process only relevant data for training\n",
    "# in this case, so far we are only considering data for which\n",
    "# there is an alpha value in the 'response' column\n",
    "response_df = pd.read_json(fresh_data['response_df'])\n",
    "\n",
    "print('*' * 80)\n",
    "print(f'total number of responses in response_df: {len(response_df)}')\n",
    "\n",
    "# create matrix for training with items over rows and users over columns\n",
    "# as a numpy matrix\n",
    "response_matrix = SetUpDataframes.response_matrix(response_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>5</th>\n",
       "      <th>43</th>\n",
       "      <th>50</th>\n",
       "      <th>56</th>\n",
       "      <th>62</th>\n",
       "      <th>141</th>\n",
       "      <th>152</th>\n",
       "      <th>162</th>\n",
       "      <th>177</th>\n",
       "      <th>255</th>\n",
       "      <th>...</th>\n",
       "      <th>40611</th>\n",
       "      <th>40616</th>\n",
       "      <th>40628</th>\n",
       "      <th>40640</th>\n",
       "      <th>40658</th>\n",
       "      <th>40698</th>\n",
       "      <th>40704</th>\n",
       "      <th>40705</th>\n",
       "      <th>40717</th>\n",
       "      <th>40776</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 2967 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id      5      43     50     56     62     141    152    162    177    \\\n",
       "question_id                                                                  \n",
       "3              NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4              NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "5              NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "7              NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "8              NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...            ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "445            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "446            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "447            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "448            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "449            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "user_id      255    ...  40611  40616  40628  40640  40658  40698  40704  \\\n",
       "question_id         ...                                                    \n",
       "3              NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4              NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "5              NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "7              NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "8              NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...            ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "445            NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "446            NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "447            NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "448            NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "449            NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "user_id      40705  40717  40776  \n",
       "question_id                       \n",
       "3              NaN    NaN    NaN  \n",
       "4              NaN    NaN    NaN  \n",
       "5              NaN    NaN    NaN  \n",
       "7              NaN    NaN    NaN  \n",
       "8              NaN    NaN    NaN  \n",
       "...            ...    ...    ...  \n",
       "445            NaN    NaN    NaN  \n",
       "446            NaN    NaN    NaN  \n",
       "447            NaN    NaN    NaN  \n",
       "448            NaN    NaN    NaN  \n",
       "449            NaN    NaN    NaN  \n",
       "\n",
       "[320 rows x 2967 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan,  4., nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_matrix.loc[:,40776].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=12000\n",
    "lr=0.00001\n",
    "alpha=0.\n",
    "depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "training recommendation model for 12000 epochs with learning rate 1e-05 and \n",
      "hyperparameters regularization: 0.0 / latent features: 2\n",
      "********************************************************************************\n",
      "Epoch 00001 / train loss 4.707532 / test loss 5.018488\n",
      "Epoch 00101 / train loss 0.624641 / test loss 0.618706\n",
      "Epoch 00201 / train loss 0.614707 / test loss 0.610152\n",
      "Epoch 00301 / train loss 0.605526 / test loss 0.603035\n",
      "Epoch 00401 / train loss 0.597007 / test loss 0.596514\n",
      "Epoch 00501 / train loss 0.589088 / test loss 0.590530\n",
      "Epoch 00601 / train loss 0.581713 / test loss 0.585033\n",
      "Epoch 00701 / train loss 0.574833 / test loss 0.579977\n",
      "Epoch 00801 / train loss 0.568402 / test loss 0.575322\n",
      "Epoch 00901 / train loss 0.562380 / test loss 0.571030\n",
      "Epoch 01001 / train loss 0.556732 / test loss 0.567069\n",
      "Epoch 01101 / train loss 0.551423 / test loss 0.563409\n",
      "Epoch 01201 / train loss 0.546425 / test loss 0.560022\n",
      "Epoch 01301 / train loss 0.541711 / test loss 0.556884\n",
      "Epoch 01401 / train loss 0.537256 / test loss 0.553973\n",
      "Epoch 01501 / train loss 0.533039 / test loss 0.551270\n",
      "Epoch 01601 / train loss 0.529041 / test loss 0.548756\n",
      "Epoch 01701 / train loss 0.525243 / test loss 0.546416\n",
      "Epoch 01801 / train loss 0.521629 / test loss 0.544233\n",
      "Epoch 01901 / train loss 0.518185 / test loss 0.542196\n",
      "Epoch 02001 / train loss 0.514897 / test loss 0.540292\n",
      "Epoch 02101 / train loss 0.511754 / test loss 0.538510\n",
      "Epoch 02201 / train loss 0.508743 / test loss 0.536841\n",
      "Epoch 02301 / train loss 0.505856 / test loss 0.535274\n",
      "Epoch 02401 / train loss 0.503083 / test loss 0.533803\n",
      "Epoch 02501 / train loss 0.500416 / test loss 0.532419\n",
      "Epoch 02601 / train loss 0.497848 / test loss 0.531116\n",
      "Epoch 02701 / train loss 0.495371 / test loss 0.529888\n",
      "Epoch 02801 / train loss 0.492979 / test loss 0.528729\n",
      "Epoch 02901 / train loss 0.490666 / test loss 0.527634\n",
      "Epoch 03001 / train loss 0.488428 / test loss 0.526598\n",
      "Epoch 03101 / train loss 0.486259 / test loss 0.525617\n",
      "Epoch 03201 / train loss 0.484155 / test loss 0.524687\n",
      "Epoch 03301 / train loss 0.482112 / test loss 0.523804\n",
      "Epoch 03401 / train loss 0.480126 / test loss 0.522966\n",
      "Epoch 03501 / train loss 0.478194 / test loss 0.522170\n",
      "Epoch 03601 / train loss 0.476312 / test loss 0.521411\n",
      "Epoch 03701 / train loss 0.474478 / test loss 0.520689\n",
      "Epoch 03801 / train loss 0.472688 / test loss 0.520001\n",
      "Epoch 03901 / train loss 0.470942 / test loss 0.519344\n",
      "Epoch 04001 / train loss 0.469235 / test loss 0.518716\n",
      "Epoch 04101 / train loss 0.467566 / test loss 0.518117\n",
      "Epoch 04201 / train loss 0.465933 / test loss 0.517544\n",
      "Epoch 04301 / train loss 0.464335 / test loss 0.516995\n",
      "Epoch 04401 / train loss 0.462769 / test loss 0.516470\n",
      "Epoch 04501 / train loss 0.461234 / test loss 0.515966\n",
      "Epoch 04601 / train loss 0.459729 / test loss 0.515483\n",
      "Epoch 04701 / train loss 0.458251 / test loss 0.515020\n",
      "Epoch 04801 / train loss 0.456801 / test loss 0.514575\n",
      "Epoch 04901 / train loss 0.455376 / test loss 0.514148\n",
      "Epoch 05001 / train loss 0.453975 / test loss 0.513738\n",
      "Epoch 05101 / train loss 0.452598 / test loss 0.513343\n",
      "Epoch 05201 / train loss 0.451244 / test loss 0.512963\n",
      "Epoch 05301 / train loss 0.449911 / test loss 0.512598\n",
      "Epoch 05401 / train loss 0.448599 / test loss 0.512246\n",
      "Epoch 05501 / train loss 0.447307 / test loss 0.511908\n",
      "Epoch 05601 / train loss 0.446034 / test loss 0.511582\n",
      "Epoch 05701 / train loss 0.444780 / test loss 0.511267\n",
      "Epoch 05801 / train loss 0.443543 / test loss 0.510964\n",
      "Epoch 05901 / train loss 0.442324 / test loss 0.510672\n",
      "Epoch 06001 / train loss 0.441121 / test loss 0.510391\n",
      "Epoch 06101 / train loss 0.439934 / test loss 0.510119\n",
      "Epoch 06201 / train loss 0.438763 / test loss 0.509857\n",
      "Epoch 06301 / train loss 0.437606 / test loss 0.509604\n",
      "Epoch 06401 / train loss 0.436464 / test loss 0.509360\n",
      "Epoch 06501 / train loss 0.435336 / test loss 0.509125\n",
      "Epoch 06601 / train loss 0.434222 / test loss 0.508897\n",
      "Epoch 06701 / train loss 0.433120 / test loss 0.508678\n",
      "Epoch 06801 / train loss 0.432032 / test loss 0.508466\n",
      "Epoch 06901 / train loss 0.430956 / test loss 0.508262\n",
      "Epoch 07001 / train loss 0.429891 / test loss 0.508065\n",
      "Epoch 07101 / train loss 0.428839 / test loss 0.507874\n",
      "Epoch 07201 / train loss 0.427797 / test loss 0.507690\n",
      "Epoch 07301 / train loss 0.426767 / test loss 0.507513\n",
      "Epoch 07401 / train loss 0.425748 / test loss 0.507342\n",
      "Epoch 07501 / train loss 0.424738 / test loss 0.507177\n",
      "Epoch 07601 / train loss 0.423739 / test loss 0.507017\n",
      "Epoch 07701 / train loss 0.422750 / test loss 0.506864\n",
      "Epoch 07801 / train loss 0.421770 / test loss 0.506716\n",
      "Epoch 07901 / train loss 0.420800 / test loss 0.506573\n",
      "Epoch 08001 / train loss 0.419838 / test loss 0.506435\n",
      "Epoch 08101 / train loss 0.418886 / test loss 0.506303\n",
      "Epoch 08201 / train loss 0.417941 / test loss 0.506175\n",
      "Epoch 08301 / train loss 0.417006 / test loss 0.506053\n",
      "Epoch 08401 / train loss 0.416078 / test loss 0.505935\n",
      "Epoch 08501 / train loss 0.415158 / test loss 0.505821\n",
      "Epoch 08601 / train loss 0.414245 / test loss 0.505713\n",
      "Epoch 08701 / train loss 0.413340 / test loss 0.505608\n",
      "Epoch 08801 / train loss 0.412443 / test loss 0.505508\n",
      "Epoch 08901 / train loss 0.411552 / test loss 0.505412\n",
      "Epoch 09001 / train loss 0.410667 / test loss 0.505321\n",
      "Epoch 09101 / train loss 0.409790 / test loss 0.505233\n",
      "Epoch 09201 / train loss 0.408918 / test loss 0.505150\n",
      "Epoch 09301 / train loss 0.408053 / test loss 0.505070\n",
      "Epoch 09401 / train loss 0.407193 / test loss 0.504995\n",
      "Epoch 09501 / train loss 0.406339 / test loss 0.504924\n",
      "Epoch 09601 / train loss 0.405491 / test loss 0.504856\n",
      "Epoch 09701 / train loss 0.404647 / test loss 0.504793\n",
      "Epoch 09801 / train loss 0.403809 / test loss 0.504734\n",
      "Epoch 09901 / train loss 0.402975 / test loss 0.504679\n",
      "Epoch 10001 / train loss 0.402145 / test loss 0.504627\n",
      "Epoch 10101 / train loss 0.401320 / test loss 0.504580\n",
      "Epoch 10201 / train loss 0.400499 / test loss 0.504538\n",
      "Epoch 10301 / train loss 0.399682 / test loss 0.504500\n",
      "Epoch 10401 / train loss 0.398869 / test loss 0.504466\n",
      "Epoch 10501 / train loss 0.398059 / test loss 0.504437\n",
      "Epoch 10601 / train loss 0.397252 / test loss 0.504413\n",
      "Epoch 10701 / train loss 0.396449 / test loss 0.504394\n",
      "Epoch 10801 / train loss 0.395649 / test loss 0.504381\n",
      "Epoch 10901 / train loss 0.394852 / test loss 0.504374\n",
      "Epoch 11001 / train loss 0.394058 / test loss 0.504373\n",
      "Epoch 11101 / train loss 0.393267 / test loss 0.504380\n",
      "Epoch 11201 / train loss 0.392480 / test loss 0.504393\n",
      "Epoch 11301 / train loss 0.391696 / test loss 0.504415\n",
      "Epoch 11401 / train loss 0.390917 / test loss 0.504447\n",
      "Epoch 11501 / train loss 0.390142 / test loss 0.504488\n",
      "Epoch 11601 / train loss 0.389373 / test loss 0.504540\n",
      "Epoch 11701 / train loss 0.388611 / test loss 0.504606\n",
      "Epoch 11801 / train loss 0.387857 / test loss 0.504685\n",
      "Epoch 11901 / train loss 0.387112 / test loss 0.504780\n",
      "********************************************************************************\n",
      "training finished. final losses are\n",
      "Epoch 12000 / train loss 0.386386 / test loss 0.504892\n",
      "********************************************************************************\n",
      "model has been saved to afinidata_recommender_model_specs.pkl in the local directory\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "datasets = Datasets(response_matrix)\n",
    "train_set, test_set = datasets.train_test_split(0.1)\n",
    "\n",
    "# model initialization\n",
    "model = CollaborativeFiltering()\n",
    "model.actors = {\n",
    "    'users': response_matrix.columns.values,\n",
    "    'items': response_matrix.index.values\n",
    "}\n",
    "model.n_items = len(datasets.posts)\n",
    "model.n_users = len(datasets.users)\n",
    "\n",
    "model.train(\n",
    "    train_matrix=train_set,\n",
    "    test_matrix=test_set,\n",
    "    epochs=epochs,\n",
    "    alpha=alpha,\n",
    "    n_features=depth,\n",
    "    lr=lr,\n",
    "    resume=False\n",
    ")\n",
    "\n",
    "print('*' * 80)\n",
    "model.save_model(f'afinidata_recommender_model_specs')\n",
    "print(f'model has been saved to afinidata_recommender_model_specs.pkl in the local directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predictions  response     score  normalized  probabilities\n",
      "area_id                                                            \n",
      "cogni       2.989733  1.593750  1.593750   -1.117530       0.721700\n",
      "motor       3.088059  3.294118  3.294118    0.805917       0.105442\n",
      "socio       3.076035  2.857143  2.857143    0.311613       0.172857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>question_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>area_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3.629393</td>\n",
       "      <td>266</td>\n",
       "      <td>279</td>\n",
       "      <td>cogni</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3.571731</td>\n",
       "      <td>265</td>\n",
       "      <td>278</td>\n",
       "      <td>cogni</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3.488403</td>\n",
       "      <td>291</td>\n",
       "      <td>304</td>\n",
       "      <td>cogni</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3.468605</td>\n",
       "      <td>287</td>\n",
       "      <td>300</td>\n",
       "      <td>cogni</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3.433095</td>\n",
       "      <td>286</td>\n",
       "      <td>299</td>\n",
       "      <td>cogni</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3.418308</td>\n",
       "      <td>290</td>\n",
       "      <td>303</td>\n",
       "      <td>cogni</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>3.278352</td>\n",
       "      <td>366</td>\n",
       "      <td>380</td>\n",
       "      <td>cogni</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.273778</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>cogni</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>3.252049</td>\n",
       "      <td>325</td>\n",
       "      <td>338</td>\n",
       "      <td>cogni</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3.236485</td>\n",
       "      <td>309</td>\n",
       "      <td>322</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3.212554</td>\n",
       "      <td>260</td>\n",
       "      <td>274</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3.196374</td>\n",
       "      <td>273</td>\n",
       "      <td>285</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.180171</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>3.161430</td>\n",
       "      <td>327</td>\n",
       "      <td>340</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3.120506</td>\n",
       "      <td>347</td>\n",
       "      <td>360</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>3.117354</td>\n",
       "      <td>376</td>\n",
       "      <td>390</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3.111430</td>\n",
       "      <td>294</td>\n",
       "      <td>307</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3.108907</td>\n",
       "      <td>285</td>\n",
       "      <td>298</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>3.094600</td>\n",
       "      <td>322</td>\n",
       "      <td>335</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>3.009626</td>\n",
       "      <td>368</td>\n",
       "      <td>382</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2.956908</td>\n",
       "      <td>278</td>\n",
       "      <td>291</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2.882017</td>\n",
       "      <td>264</td>\n",
       "      <td>276</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2.787908</td>\n",
       "      <td>367</td>\n",
       "      <td>381</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2.691403</td>\n",
       "      <td>321</td>\n",
       "      <td>334</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2.667727</td>\n",
       "      <td>250</td>\n",
       "      <td>262</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2.659968</td>\n",
       "      <td>365</td>\n",
       "      <td>379</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.641333</td>\n",
       "      <td>279</td>\n",
       "      <td>292</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2.609133</td>\n",
       "      <td>235</td>\n",
       "      <td>245</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2.550507</td>\n",
       "      <td>352</td>\n",
       "      <td>365</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2.457813</td>\n",
       "      <td>328</td>\n",
       "      <td>341</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2.441959</td>\n",
       "      <td>371</td>\n",
       "      <td>385</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2.440050</td>\n",
       "      <td>288</td>\n",
       "      <td>301</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2.273111</td>\n",
       "      <td>370</td>\n",
       "      <td>384</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2.227950</td>\n",
       "      <td>373</td>\n",
       "      <td>387</td>\n",
       "      <td>cogni</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predictions  question_id  post_id area_id  response\n",
       "135     3.629393          266      279   cogni       4.0\n",
       "134     3.571731          265      278   cogni       4.0\n",
       "157     3.488403          291      304   cogni       3.0\n",
       "153     3.468605          287      300   cogni       3.0\n",
       "152     3.433095          286      299   cogni       NaN\n",
       "156     3.418308          290      303   cogni       4.0\n",
       "218     3.278352          366      380   cogni       NaN\n",
       "14      3.273778           30       15   cogni       4.0\n",
       "184     3.252049          325      338   cogni       4.0\n",
       "170     3.236485          309      322   cogni       1.0\n",
       "130     3.212554          260      274   cogni       1.0\n",
       "140     3.196374          273      285   cogni       1.0\n",
       "27      3.180171           63       86   cogni       1.0\n",
       "186     3.161430          327      340   cogni       1.0\n",
       "203     3.120506          347      360   cogni       1.0\n",
       "227     3.117354          376      390   cogni       1.0\n",
       "159     3.111430          294      307   cogni       1.0\n",
       "151     3.108907          285      298   cogni       1.0\n",
       "181     3.094600          322      335   cogni       1.0\n",
       "220     3.009626          368      382   cogni       1.0\n",
       "145     2.956908          278      291   cogni       1.0\n",
       "133     2.882017          264      276   cogni       1.0\n",
       "219     2.787908          367      381   cogni       1.0\n",
       "180     2.691403          321      334   cogni       1.0\n",
       "122     2.667727          250      262   cogni       1.0\n",
       "217     2.659968          365      379   cogni       1.0\n",
       "146     2.641333          279      292   cogni       1.0\n",
       "112     2.609133          235      245   cogni       1.0\n",
       "206     2.550507          352      365   cogni       1.0\n",
       "187     2.457813          328      341   cogni       1.0\n",
       "222     2.441959          371      385   cogni       1.0\n",
       "154     2.440050          288      301   cogni       1.0\n",
       "221     2.273111          370      384   cogni       1.0\n",
       "224     2.227950          373      387   cogni       1.0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(recommend(40776, 0, fresh_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predictions  response     score  normalized  probabilities\n",
      "area_id                                                            \n",
      "cogni       2.989733  1.612903  1.612903   -1.116614            1.0\n",
      "predictions    2.22795\n",
      "question_id        373\n",
      "post_id            387\n",
      "area_id          cogni\n",
      "response           NaN\n",
      "Name: 224, dtype: object\n"
     ]
    }
   ],
   "source": [
    "register_recommendation_response(40776, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
